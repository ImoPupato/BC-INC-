_La información del dataset está disponible en [GSE186901](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE186901)._  
El estudio consiste en un análisis genómico y transcriptómico integral en pacientes asiáticos con cáncer de mama metastásico con y sin resistencia, tratados con palbociclib. Limitación: administración en conjunto a terapia endocrina, RNASeq en FPKM (Fragments Per Kilobase Million).  (Estudio asociado: EGAS00001005736). n = 24.  
Como ya es sabido, el análisis de esxpresión diferencial no es recomendado a partir de las FPKM, de todas formas al no contar con las _raw counts_ se procede a realizar transformación previa de los datos.  
### Carga de librerías
```R
library(tidyverse)
library(edgeR)
library(caret)
library(glmnet)
library(ReactomePA)
library(enrichplot)
library("msigdbr")
library(rpart)
library(rpart.plot)
library(randomForest)
library("org.Hs.eg.db")
```
### Carga y exploración del dataset
```R
data <- read.delim("~/GSE186901_palbo_geo_tpm_mat.txt")
names(data)
data<-data[,1:55] # seleccionamos solamente las RNASeq, tienen en su nombre "WTS"
```
### Selección de pacientes con información antes y despues del tratamiento con Palbociclib (muestras dependientes)
```R
ids_pacientes <- sub("_(Baseline|PD)_WTS$", "", colnames(data))
conteo_pacientes <- table(ids_pacientes)
pacientes_con_ambos <- names(conteo_pacientes[conteo_pacientes == 2]) # Seleccionamos los pacientes que tienen ambos tratamientos, es decir que aparecen 2 veces
columnas_filtradas <- colnames(data)[ids_pacientes %in% pacientes_con_ambos] # Ahora filtramos solo las columnas cuyos IDs están en la lista de pacientes con ambos tratamientos y regeneramos el id completo
data_filtrada <- data[, columnas_filtradas, drop = FALSE]
rownames(data_filtrada)<-rownames(data)
```
### Cálculo de pseudo-counts a partir de las FPKM
```R
seq_depth <- 1e6  # Ajusta según el promedio de lecturas esperadas
pseudo_counts <- round(data_filtrada * seq_depth / 1e6)
```
### Análisis de expresión diferencial
```R
group <- factor(rep(c("Post", "Pre"),12)) # etiquetas Pre y Post tratamiento
dge <- DGEList(counts = pseudo_counts, group = group) # Creamos el objeto DGEList de edgeR
keep <- filterByExpr(dge) # Filtramos aquellos genes con muy pocos conteos
dge <- dge[keep, , keep.lib.sizes=FALSE]
dge <- calcNormFactors(dge) # Normalizamos TMM
design <- model.matrix(~group) # Generamos el diseño experimental
dge <- estimateDisp(dge, design) # Estimamos la dispersión
fit <- glmFit(dge, design) # Ajustamos el modelo y continuamos con el análisis de los resultados
lrt <- glmLRT(fit, coef=2)  # nos interesa el post
```
### Análisis de los genes más significativos
```R
top_genes <- topTags(lrt, n=Inf) # Resultados ordenados por significancia
top_genes <- topTags(lrt, n=Inf)$table
top_genes$GeneName <- rownames(top_genes)
differential_genes <- top_genes[top_genes$FDR < 0.1, ] # Extraemos los genes diferenciales significativos y los renombrarmos segun symbol
rownames(data)<-data$gene_name
differential_genes$GeneName <- rownames(data)[as.numeric(rownames(differential_genes))]
```
#### Tabla de genes con un FDR<0.1
|logFC|logCPM|       LR|       PValue|        FDR |GeneName|
| -------- |-------- | -------- | -------- |-------- | -------- |
|-2.762836 |6.630676 |21.41108 | 3.706234e-06|0.02396822|      FOS|
|-1.730297 |6.710240 |17.15024 |3.453661e-05 |0.07513436  | NFKBIZ|
|-1.585299 |5.429205 |17.13284 |3.485435e-05 |0.07513436  | CAPN13|
|2.049943  |9.499147 |16.48791 |4.896127e-05 |0.07915814   |  SPP1|
|-1.921147 |7.594425 |15.80156 |7.034463e-05 |0.08563172  |AMY2B|
|-1.891164 |6.097965 |15.28936 |9.223469e-05 |0.08563172  | ACACB|
|-1.152733 |5.128527 |15.28007 |9.268935e-05 |0.08563172  |    PSD4|

### Análisis Lasso
#### Preparación de los datos
```R
data_filtrada$gene_name<-data$gene_name
names_ids_df<-data.frame(gene_name=c(differential_genes$GeneName))
Genes<- as.data.frame(t(merge(names_ids_df,data_filtrada,by="gene_name")))
colnames(Genes)<-Genes[1,]
Genes<-Genes[-c(1,26),]
Genes$Res.<-c(rep(c(0,1),12))
Genes <- apply(Genes, 2, as.numeric)
Genes <- as.data.frame(Genes)
```
#### Objetos para llevar adelante la regresión
```R
X<- model.matrix(Res. ~ .,Genes)[,-1] # evita redundancia
Y<-c(Genes$Res.)
lasso_model <- cv.glmnet(X, Y, alpha = 1, nfolds = 3)
lasso_pred <- predict(lasso_model, newx = X, s = "lambda.min")
```
#### Indicadores del ajuste
```R
rmse <- function(actual, predicted) {
  sqrt(mean((actual - predicted)^2))}
r2 <- function(actual, predicted) {
  1 - sum((actual - predicted)^2) / sum((actual - mean(actual))^2)}
rmse(Y, lasso_pred)
r2(Y, lasso_pred)
```  
Se obtuvo un R<sup>2</sup> = 0.5689784 y un RMSE = 0.3282612. Cuanto más cercano a 1 es el R<sup>2</sup>, mayor porcentaje de explicación y cuanto más cercano a 0 es el RMSE, mas preciso.  
#### Coeficientes de la regresión
```R
df_coef<- coef(lasso_model) %>%
  as.matrix()%>%
  as_tibble(rownames="predictor") 

genes_predictores_lasso<-df_coef %>%
  filter( predictor!="(Intercept)",
          s1!=0)
colnames(genes_predictores_lasso)<-c("Gene","Coef.")
```
#### Tabla de coeficientes lasso
| Gen predictor| Coeficiente|
|--------------|-------------|
|Ordenada|  0.410| 
|ACACB |       0|
|AMY2B  |      0       |
|CAPN13  |    -0.00119 |
|FOS      |   -0.000826|
|NFKBIZ    |   0       |
|PSD4       | -0.00111 |
|SPP1       |  0.000568|

### Análisis predictivo: arbol de decisión
#### Manipulación de los datos para generar las matrices de entrenamiento y prueba
```R
Genes$Res.<-factor(Genes$Res.)
set.seed(12345)
trainIndex <- createDataPartition(Genes$Res., p = .8, list = FALSE, times = 1)
TRAIN <- Genes[trainIndex, ] # 10
TEST <- Genes[-trainIndex, ] # 2
```
#### Creación del modelo y prueba
```R
arbol_1<-rpart(
  formula=Res.~.,
  data=TRAIN)
prediccion_1<-predict(arbol_1, newdata = TEST, type = "class")
confusionMatrix(prediccion_1, TEST[["Res."]])
plot(arbol_1)
```
#### Resultado del modelo en r:
```R
n= 20 
node), split, n, loss, yval, (yprob)
      * denotes terminal node
1) root 20 10 0 (0.5000000 0.5000000)  
  2) SPP1< 164.525 9  1 0 (0.8888889 0.1111111) *
  3) SPP1>=164.525 11  2 1 (0.1818182 0.8181818) *
```
### Análisis aprendizaje automatizado
```R
arbol_2<-randomForest(
  formula=Res.~.,
  data=TRAIN,
  ntree=50,
  keep.inbag=TRUE)
prediccion_2<-predict(arbol_2, newdata = TEST, type = "class")
confusionMatrix(prediccion_2, TEST[["Res."]])
```
#### Resultado del modelo en r:
```R
Call:
 randomForest(formula = Res. ~ ., data = TRAIN, ntree = 50, keep.inbag = TRUE) 
               Type of random forest: classification
                     Number of trees: 50
No. of variables tried at each split: 2
        OOB estimate of  error rate: 25%
Confusion matrix:
  0 1 class.error
0 8 2         0.2
1 3 7         0.3
```
